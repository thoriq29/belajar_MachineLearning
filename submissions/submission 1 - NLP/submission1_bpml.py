# -*- coding: utf-8 -*-
"""Submission1_BPML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rpdkoTVsMtZfzf3F_iQUNLzd-aYs7IVg
"""

!wget --no-check-certificate \
  https://firebasestorage.googleapis.com/v0/b/writehere-13.appspot.com/o/Consumer_Complaints.csv?alt=media&token=06497397-7e47-4919-8a81-8bb8a5ee3268

import pandas as pd
df = pd.read_csv('Consumer_Complaints.csv?alt=media')
df.drop(df.index[2500:670593], inplace=True)
df.head()

Product = pd.get_dummies(df.Product)
df_baru = pd.concat([df, Product], axis=1)
df_baru = df_baru.drop(columns=[
          'Date received', 'Product', 'Sub-product', 'Sub-issue','Consumer complaint narrative',
          'Company public response', 'Company', 'State', 'ZIP code', 'Tags', 'Timely response?',
          'Consumer consent provided?', 'Submitted via', 'Date sent to company', 'Company response to consumer',
          'Timely response?', 'Consumer disputed?', 'Complaint ID'
        ])
df_baru

news = df_baru['Issue'].values
label = df_baru[[
            'Bank account or service', 'Consumer Loan', 'Credit card', 'Credit reporting',
            'Debt collection', 'Money transfers', 'Mortgage', 'Student loan']].values

from sklearn.model_selection import train_test_split
news_train, news_test, label_train, label_test = train_test_split(news, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(news_train) 
tokenizer.fit_on_texts(news_test)
 
sekuens_latih = tokenizer.texts_to_sequences(news_train)
sekuens_test = tokenizer.texts_to_sequences(news_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(8, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

class customCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.99 and logs.get('val_accuracy')>0.99):
      print("\nAkurasi pada training set dan validation set telah mencapai >90%!")
      self.model.stop_training = True
callbacks = customCallback()

num_epochs = 50
history = model.fit(padded_latih, label_train, epochs=num_epochs, 
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()